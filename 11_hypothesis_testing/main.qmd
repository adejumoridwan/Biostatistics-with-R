---
title: "Hypothesis Testing"
author: "Adejumo Ridwan Suleiman"
format: revealjs
---

# What is a Statistical Hypothesis?


## What is Hypothesis?

Statement about an expected relationship between one or more independent variables and a dependent variable

## Types of Hypothesis

- **Research Hypothesis:** Statement that motivates the research

- **Statistical Hypothesis:** Statements that can be evaluated by statistical techniques.

## What is Statistical Hypothesis?

- Statement or fact not yet tested

- Characteristics of a population not yet verified

- For example, smokers are at risk of devloping lung cancer


# Null and Alternative Hypothesis

## Null Hypothesis ($H_0$)

- Statement forming basis of investigation

- Statement of **no difference**, **no association**, **no effect** or **statement of equality**.

- Examples:

    - $H_0$: The average weight of patients in the clinic is not equal to 60kg
    - $H_0$: Smokers have no risk of getting lung cancer

- This hypothesis is either **rejected** or **not rejected**

## Alternative Hypothesis ($H_1$)

- Complement or alternative of $H_0$

- Statement of **inequality**

- Investigators will accept if $H_0$ is rejected 

- Examples:
    - $H_1$: The average weight of patients in the clinic is more that 60kg
    - $H_1$: Smokers have a higher risk of getting lung cancer

## Steps in Hypothesis Testing

1. State the null hypothesis ($H_0$)

2. State the alternative hypothesis ($H_1$)

3. State the level of significane ($\alpha$)

4. Choose the appropriate test statistic

5. Evaluate the test statistic

6. Decision making

# Errors in Hypotheis Testing



## Type I Error

- Rejecting a true null hypothesis

- Probability of committing a type I error is denoted by $\alpha$

- Incorrectly concluding that a difference exists, when actually there is no difference

- A false positive decision

## Type II Error

- Accepting a false null hypothesis

- Probability of committing a type II error is denoted by $\beta$

- Incorrectly concluding that no difference exists, when actually there is a difference

- A false negative decision




## Errrors Compliment 

**Confidence level ($1-\alpha$)**


- Tests the ability to accept the null hypothesis when it is actually true


**Power of a test ($1-\beta$)**

- Power of a test

- Tests the ability to reject a null hypothesis when it is false

## Level of significance

- Maximum probability of committing a type I error

- Mostly 0.05

- Denoted by $\alpha$



# P-value

## P-value

- Measure of the amount of evidence we have against the null hypothesis


- The smaller the p-value the more the evidence against $H_0$ and vice versa

## P-value Interpretation

- If $\alpha=0.05$, and $\text{p-value}<0.03$, this implies statistical significance.

- This means that the probability of getting an observed effect if truly there was no effect is 3%

- In other words, there is a 3% probability that an observed effect is likely by chance.

## Decision Making 

| $\text{p-value}<\alpha$ | $\text{p-value}\ge\alpha$ |
| --- | --- |
| Difference is unlikely due to chance | Difference might be due to chance |

# Choice of Test Statistic

## 

- Test Statistic tests for a statistical hypothesis

- Depends:

    - Study objective

    - Study design

    - Variable type

    - Sample size and sampling method

    - Sampling distribution

## Selecting appropriate Test Statistic

- Relationship between two qualitative variables
    - **Z-test** or **chi-square test** (for difference in proportion)
    - **Chi-square test** (for association/independence)

- Relationship between one qualitative and one quantitative variable
    - two groups - **t-test**
    - more than two groups - **F-test**

- Relatioship between two quantitative variables
    - Correlation analysis
    - Linear regression analysis



## Types of parametric tests

**Parametric**

Assumes measurements are **normally distributed**

**Non-parametric**

- Assumes measurements are not **normally distributed**

- Small sample size, nominal or ordinal data

- Weaker than parametric tests

##

![](images/statistical_tests.png)



